{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfdocument import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import io\n",
    "import jieba\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "from FlagEmbedding import FlagModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePDF(PDF_path):\n",
    "    flag = False\n",
    "    if 'AZ' in PDF_path:\n",
    "        flag = True\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager,fake_file_handle)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager,converter)\n",
    "    with open(PDF_path,'rb') as fh:\n",
    "        for n_page,page in enumerate(PDFPage.get_pages(fh,caching=True,check_extractable=False)):\n",
    "            if flag:\n",
    "                if n_page < 2:\n",
    "                    continue\n",
    "            page_interpreter.process_page(page)\n",
    "        text = fake_file_handle.getvalue()\n",
    "    converter.close()\n",
    "    fake_file_handle.close()\n",
    "    if text:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_content_from_text(text,drop_content):\n",
    "    for content in drop_content:\n",
    "        text = text.replace(content,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 110/120 [00:43<00:06,  1.59it/s]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ01.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      " 92%|█████████▎| 111/120 [00:44<00:06,  1.49it/s]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ02.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      " 93%|█████████▎| 112/120 [00:45<00:07,  1.06it/s]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ03.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      " 94%|█████████▍| 113/120 [00:47<00:07,  1.00s/it]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ04.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      " 95%|█████████▌| 114/120 [00:47<00:05,  1.01it/s]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ05.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      " 96%|█████████▌| 115/120 [00:49<00:06,  1.20s/it]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ06.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      " 97%|█████████▋| 116/120 [00:51<00:05,  1.27s/it]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ07.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      " 98%|█████████▊| 117/120 [00:52<00:03,  1.26s/it]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ08.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      " 98%|█████████▊| 118/120 [00:53<00:02,  1.31s/it]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ09.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      " 99%|█████████▉| 119/120 [00:55<00:01,  1.43s/it]The PDF <_io.BufferedReader name='data/A榜/A_document\\\\AZ10.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "100%|██████████| 120/120 [00:56<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "document_root = r'data/A榜/A_document'\n",
    "docs = os.listdir(document_root)\n",
    "\n",
    "knowledge = []\n",
    "\n",
    "drop_content = ['\\x0c',\n",
    "                '本文档为2024CCFBDCI比赛用语料的一部分。部分文档使用大语言模型改写生成，内容可能与现实情况不符，可能不具备现实意义，仅允许在本次比赛中使用。']\n",
    "\n",
    "for doc in tqdm(docs):\n",
    "    # if doc != 'AZ01.pdf':\n",
    "    #     continue\n",
    "    doc_path = os.path.join(document_root,doc)\n",
    "    text = drop_content_from_text(parsePDF(doc_path),drop_content)\n",
    "    knowledge.append(text)\n",
    "\n",
    "knowledge = ''.join(knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "# chunks = text_splitter.split_documents(knowledge)\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = token_splitter.split_text(knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeDataBase:\n",
    "    def __init__(self,chunks) -> None:\n",
    "        self.model = FlagModel('BAAI/bge-large-zh-v1.5',\n",
    "                  query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
    "                  use_fp16=True)\n",
    "        self.chunks = [drop_content_from_text(chunk,'�') for chunk in chunks]\n",
    "        self.db = self.create_db(chunks)\n",
    "\n",
    "    def create_db(self,chunks):\n",
    "        print('create db..')\n",
    "        db = []\n",
    "        for chunk in tqdm(chunks):\n",
    "            db.append(self.model.encode(chunk))\n",
    "        return db\n",
    "\n",
    "    def search(self,query,n=5):\n",
    "        query_embedding = self.model.encode(query)\n",
    "        similarity_scores = [(doc_id, cosine_similarity(query_embedding.reshape(1,-1), doc.reshape(1,-1))[0][0]) \n",
    "                            for doc_id, doc in enumerate(self.db)]\n",
    "        top_n_results = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[:n]\n",
    "        return top_n_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create db..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3449/3449 [33:08<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "kdb = KnowledgeDataBase(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'data/A榜/A_question.csv'\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# df_test['answer'] = df_test['question'].apply(lambda x:''.join([kdb.chunks[id] for id,score in kdb.search(x,n=5)]))\n",
    "# df_test['embedding'] = df_test['answer'].apply(lambda x:kdb.model.encode(x))\n",
    "# df_test.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['id'] = df_test['question'].apply(lambda x:[id for id,score in kdb.search(x,n=1)][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1115\n",
       "1     1623\n",
       "2     1504\n",
       "3     1506\n",
       "4     1571\n",
       "      ... \n",
       "95     817\n",
       "96     821\n",
       "97     685\n",
       "98     694\n",
       "99     699\n",
       "Name: id, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['answer'] = df_test['id'].apply(lambda x:kdb.chunks[x])\n",
    "df_test['embedding'] = df_test['id'].apply(lambda x:str(list(kdb.db[x]))[1:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('result.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
